# SignVerse MVP Plan v2.1
## Video-Only, Risk-Mitigated Approach

**Version**: 2.1
**Date**: 2026-01-10
**Status**: Approved

---

## Executive Summary

This plan uses a **video-only approach** for sign demonstrations - no 3D avatars in MVP. This dramatically simplifies development while providing authentic, effective learning content.

| Issue | Original Risk | Mitigation |
|-------|---------------|------------|
| Biometric privacy | Legal liability | Explicit consent + differential privacy |
| Emergency scenario | Safety liability | **Removed from MVP** |
| 3D Avatar complexity | Development time, uncanny valley | **Video-only for MVP** |
| Hand occlusion | Core functionality | Start with fingerspelling (no occlusion) |
| Unrealistic timeline | Project failure | Phase gates with go/no-go decisions |

**Key Decisions**:
1. **Video-only**: Pre-recorded videos of native signer (no Unity, no RealityKit for MVP)
2. **Scope reduction**: 4 scenarios (emergency removed)
3. **Privacy-first**: Biometric consent + on-device processing
4. **Go/No-Go gates**: Each phase has exit criteria before proceeding
5. **Pure iOS**: SwiftUI + AVFoundation + Vision Framework only

---

## Revised Core Concept: "The Learning Mirror"

### What Changed
- **Removed**: "Emergency" scenario (liability too high)
- **Added**: Explicit biometric data consent flow
- **Simplified**: Start with fingerspelling, not full signs

### MVP Scenarios (4, not 5)

| # | Scenario | Signs | Complexity |
|---|----------|-------|------------|
| 1 | **Fingerspelling** | A-Z (26) | Low - static poses |
| 2 | **Needs Check** | TIRED, HUNGRY, PAIN, OKAY, THIRSTY | Medium - single motion |
| 3 | **Requests** | WATER, COFFEE, HELP, PLEASE, THANK-YOU | Medium - single motion |
| 4 | **Affection** | LOVE, HUG, GOOD, YES, NO | Medium - some two-handed |

**Total MVP vocabulary**: 26 letters + 15 words = 41 signs

### Why Emergency Was Removed

```
RISK ASSESSMENT: Emergency Scenario
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Scenario: User signs "HELP" in medical emergency
Recognition accuracy needed: >99.9%
Current achievable accuracy: ~85%
Failure mode: User believes help is coming, no one responds
Liability: Potentially life-threatening

DECISION: Remove until recognition exceeds 99% on safety-critical signs
         Add back in v2.0 with redundant safety systems
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## Revised Architecture

### Privacy-First Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRIVACY ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    ON-DEVICE ONLY    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Camera     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Vision          â”‚ â”‚
â”‚  â”‚   Feed       â”‚   Never leaves        â”‚  Framework       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   device              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚          â”‚
â”‚                                          21 Keypoints        â”‚
â”‚                                                   â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              ON-DEVICE ML INFERENCE                     â”‚ â”‚
â”‚  â”‚         (CoreML - no network required)                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚          â”‚
â”‚                                          Recognized Sign     â”‚
â”‚                                                   â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              DIFFERENTIAL PRIVACY LAYER                 â”‚ â”‚
â”‚  â”‚   â€¢ Add noise to skeletal coordinates                   â”‚ â”‚
â”‚  â”‚   â€¢ Aggregate before upload (no individual samples)     â”‚ â”‚
â”‚  â”‚   â€¢ User controls: Opt-in, delete anytime               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚          â”‚
â”‚                          OPTIONAL (user consent)  â”‚          â”‚
â”‚                                                   â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                 SUPABASE (encrypted)                    â”‚â”‚
â”‚  â”‚   â€¢ Aggregated learning metrics only                    â”‚â”‚
â”‚  â”‚   â€¢ No raw skeletal data in MVP                         â”‚â”‚
â”‚  â”‚   â€¢ Progress tracking (sign attempts, accuracy)         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Biometric Consent Flow (Required)

```swift
// MUST show before ANY camera access
struct BiometricConsentView: View {
    var body: some View {
        VStack {
            Text("Important Privacy Information")
                .font(.title)

            Text("""
            SignVerse uses hand tracking to help you learn ASL.

            âš ï¸ BIOMETRIC DATA NOTICE:
            Hand movement patterns can uniquely identify individuals,
            similar to fingerprints.

            What we do:
            âœ“ Process hand tracking ON YOUR DEVICE only
            âœ“ Never upload video or images
            âœ“ Add noise to any shared data (differential privacy)
            âœ“ Let you delete all data anytime

            What we DON'T do:
            âœ— Never share raw hand coordinates
            âœ— Never sell or share biometric data
            âœ— Never use data for identification
            """)

            Toggle("I understand this is biometric data", isOn: $understood)
            Toggle("I consent to on-device hand tracking", isOn: $consentTracking)
            Toggle("I consent to sharing anonymized learning progress", isOn: $consentSharing)
        }
    }
}
```

---

## Revised Phases

### Phase 0: Technical Validation (Week 1)
**Goal**: Prove core technology works BEFORE building features

**Architecture**: Pure iOS (no Unity, no RealityKit)
- SwiftUI for UI
- AVFoundation + AVPlayer for video playback
- Vision Framework for hand tracking
- CoreML for gesture recognition

#### 0.1 Hand Tracking Test
```
GO/NO-GO CRITERIA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¡ Vision Framework detects hand in kitchen lighting
â–¡ 21 keypoints tracked at >25 FPS
â–¡ Static fingerspelling poses recognized >90%
â–¡ Works with your specific hand characteristics
â–¡ Camera + skeleton overlay displays smoothly

IF FAIL â†’ Evaluate MediaPipe or custom model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

#### 0.2 Video Playback Test
```
GO/NO-GO CRITERIA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¡ Video plays smoothly in split-screen with camera
â–¡ Slow-motion playback works (0.5x speed)
â–¡ Loop/replay controls responsive
â–¡ Memory stable during extended use (<200MB)

IF FAIL â†’ Optimize video encoding/compression
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

#### 0.3 Sample Content Creation
```
VALIDATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¡ Record 5 sample sign videos (yourself or family)
â–¡ Videos are clear and demonstrate signs effectively
â–¡ Lighting works in intended practice locations
â–¡ Video quality sufficient for learning

OUTPUT: Proof that video-based approach is viable
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Deliverables**:
- Working prototype: camera + video split-screen
- Hand tracking overlay demonstration
- 5 sample sign videos
- Go/No-Go decision for Phase 1

---

### Phase 1: Fingerspelling Foundation (Weeks 2-3)
**Goal**: Complete A-Z fingerspelling with real-time feedback

#### Why Start Here
1. **No occlusion**: Single-hand static poses
2. **Well-solved problem**: Existing datasets (ASL Alphabet: 26K images)
3. **Immediate utility**: Spell names, unknown words
4. **Measurable**: Clear accuracy metrics (26 classes)

#### Implementation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FINGERSPELLING MVP              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      REFERENCE DISPLAY          â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”                         â”‚   â”‚
â”‚  â”‚   â”‚ A â”‚  "Show me the letter A" â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”˜                         â”‚   â”‚
â”‚  â”‚   [Static hand image]           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      YOUR CAMERA                â”‚   â”‚
â”‚  â”‚                                 â”‚   â”‚
â”‚  â”‚   [Live feed + skeleton overlay]â”‚   â”‚
â”‚  â”‚                                 â”‚   â”‚
â”‚  â”‚   Confidence: 87% â†’ A âœ“        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  [â†Previous]  [Hint]  [Nextâ†’]          â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Technical Approach

```swift
// Simplified recognition for static poses
class FingerspellingRecognizer {
    // Use cosine similarity between current pose and reference poses
    // No temporal modeling needed for static letters

    func recognize(landmarks: [CGPoint]) -> (letter: Character, confidence: Float) {
        var bestMatch: Character = "?"
        var bestScore: Float = 0

        for (letter, reference) in referenceLetters {
            let score = cosineSimilarity(
                normalize(landmarks),
                normalize(reference)
            )
            if score > bestScore {
                bestScore = score
                bestMatch = letter
            }
        }

        return (bestMatch, bestScore)
    }
}
```

**Deliverables**:
- Working fingerspelling practice mode
- >90% accuracy on A-Z static poses
- Basic progress tracking (local only)

**Go/No-Go for Phase 2**:
```
â–¡ User can practice A-Z in home lighting
â–¡ Recognition accuracy >90% for static poses
â–¡ Latency <200ms from pose to feedback
â–¡ User feedback: "This is useful for spelling"
```

---

### Phase 2: Motion Signs (Weeks 4-6)
**Goal**: Add 15 motion-based signs for home communication

#### Sign Selection Criteria
1. **Single-handed preferred** (reduce occlusion)
2. **Distinct motion paths** (reduce confusion)
3. **High daily utility** (validation from user)

#### MVP Sign List

| Sign | Type | Motion | Occlusion Risk |
|------|------|--------|----------------|
| WATER | 1-hand | W-tap chin | Low |
| COFFEE | 2-hand | Grind motion | Medium |
| TIRED | 2-hand | Chest droop | Medium |
| HUNGRY | 1-hand | C-down chest | Low |
| PAIN | 2-hand | Point twist | Medium |
| OKAY | 1-hand | O-K shape | Low |
| THIRSTY | 1-hand | 1-down throat | Low |
| HELP | 2-hand | A-lift palm | Medium |
| PLEASE | 1-hand | Circle chest | Low |
| THANK-YOU | 1-hand | Chin-forward | Low |
| LOVE | 2-hand | Cross chest | **High** |
| HUG | 2-hand | Self-embrace | **High** |
| GOOD | 1-hand | Chin-palm down | Low |
| YES | 1-hand | S-nod | Low |
| NO | 1-hand | 2-snap | Low |

#### Handling High-Occlusion Signs

```swift
// For signs like LOVE and HUG where hands overlap
class OcclusionHandler {
    enum Strategy {
        case requireVisibleHand    // Only track dominant hand
        case useBodyPose           // Fall back to shoulder/elbow
        case temporalCompletion    // Predict from motion start
    }

    func handleOcclusion(for sign: Sign) -> Strategy {
        switch sign.occlusionRisk {
        case .high:
            // Accept partial recognition with lower confidence threshold
            return .temporalCompletion
        case .medium, .low:
            return .requireVisibleHand
        }
    }
}
```

#### Video Content Strategy

```
DECISION: Video-Only (Confirmed)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pre-recorded videos of native ASL signer

ADVANTAGES:
âœ“ Authentic human signing (no uncanny valley)
âœ“ Natural facial expressions (critical for ASL)
âœ“ Fast to produce ($0-500 total)
âœ“ Proven effective (how most ASL apps work)
âœ“ Simple implementation (just AVPlayer)
âœ“ No 3D framework complexity

CONTENT PLAN:
â€¢ Self-record OR hire ASL tutor for 2-3 hours
â€¢ 41 signs Ã— 10-15 seconds each = ~10 minutes of video
â€¢ Multiple angles for complex signs
â€¢ Slow-motion versions for detailed study

APP SIZE IMPACT:
â€¢ ~5MB per sign (compressed H.264)
â€¢ 41 signs = ~200MB
â€¢ Can stream from CDN if size is concern
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Deliverables**:
- 15 motion signs with recognition
- Reference videos (not 3D avatars) for demonstration
- Practice mode with feedback
- Basic spaced repetition for review

**Go/No-Go for Phase 3**:
```
â–¡ 15 signs recognized >95% accuracy
â–¡ User can have basic "conversation" with family
â–¡ Motion signs feel natural to perform
â–¡ Family members can understand user's signs
```

---

### Phase 3: Learning Loop (Weeks 7-9)
**Goal**: Gamified practice with progress tracking

#### Learning System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SPACED REPETITION SYSTEM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Sign: WATER                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Accuracy History: [95%] [88%] [92%] [97%] [94%]     â”‚   â”‚
â”‚  â”‚ Current Interval: 3 days                             â”‚   â”‚
â”‚  â”‚ Next Review: Tomorrow                                â”‚   â”‚
â”‚  â”‚ Difficulty: Easy (graduating soon)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  Sign: COFFEE                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Accuracy History: [45%] [52%] [48%] [61%]           â”‚   â”‚
â”‚  â”‚ Current Interval: 1 day                              â”‚   â”‚
â”‚  â”‚ Next Review: Today (overdue)                         â”‚   â”‚
â”‚  â”‚ Difficulty: Hard (needs practice)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  Today's Practice:                                          â”‚
â”‚  [â– â– â– â– â– â– â–‘â–‘â–‘â–‘] 6/10 signs reviewed                          â”‚
â”‚                                                             â”‚
â”‚  Streak: ğŸ”¥ 7 days                                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Progress Metrics (All Local)

```swift
struct LearningProgress: Codable {
    var signAttempts: [String: [Attempt]]
    var dailyStreak: Int
    var totalPracticeMinutes: Int
    var masteredSigns: Set<String>  // >90% over 5 sessions
    var struggingSigns: Set<String> // <70% over 3 sessions

    struct Attempt: Codable {
        let timestamp: Date
        let accuracy: Float
        let latency: TimeInterval  // Time to form sign
        let hints: Int             // How many hints needed
    }
}
```

#### Optional: Anonymous Analytics (Consent Required)

```swift
// Only if user opts in during biometric consent
struct AnonymousAnalytics {
    // Aggregated, not individual
    func reportSessionEnd() {
        let payload = [
            "session_duration_bucket": bucket(sessionMinutes), // "5-10min"
            "signs_practiced_bucket": bucket(signCount),       // "10-20"
            "avg_accuracy_bucket": bucket(avgAccuracy),        // "80-90%"
            "app_version": appVersion
        ]
        // No user ID, no timestamps, no raw accuracy values
        sendAnonymized(payload)
    }
}
```

**Deliverables**:
- Local spaced repetition system
- Progress dashboard
- Daily practice reminders (optional)
- Optional anonymized analytics

**Go/No-Go for Phase 4**:
```
â–¡ User practices daily (>5 days/week)
â–¡ Signs are being retained (accuracy improves over time)
â–¡ User reports feeling more confident
â–¡ Family communication is actually happening
```

---

### Phase 4: Conversation Mode (Weeks 10-14)
**Goal**: Two-way practice with simulated conversations

#### Conversation Flow (Pre-scripted, NOT LLM)

```
WHY NOT LLM:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. LLMs generate English, not ASL gloss
2. ASL grammar is fundamentally different
3. Hallucination risk in safety-adjacent context
4. Adds complexity and latency

MVP APPROACH: Pre-scripted conversation trees
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SCENARIO: Morning Needs Check                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Video of signer]                                          â”‚
â”‚  "Good morning! HOW YOU FEEL?"                              â”‚
â”‚  (Shows: GOOD MORNING + HOW + YOU + FEEL)                   â”‚
â”‚                                                             â”‚
â”‚  Your response options:                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  TIRED  â”‚ â”‚ HUNGRY  â”‚ â”‚  PAIN   â”‚ â”‚  OKAY   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â”‚  [Camera view - waiting for your sign]                      â”‚
â”‚                                                             â”‚
â”‚  User signs: HUNGRY                                         â”‚
â”‚  Recognition: âœ“ HUNGRY (92% confidence)                    â”‚
â”‚                                                             â”‚
â”‚  [Video response]                                           â”‚
â”‚  "Okay! BREAKFAST WANT? COFFEE WANT?"                       â”‚
â”‚  (Shows: BREAKFAST + WANT + COFFEE + WANT)                  â”‚
â”‚                                                             â”‚
â”‚  Your response options:                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ COFFEE  â”‚ â”‚  WATER  â”‚ â”‚ PLEASE  â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Scenario Scripts

```yaml
# scenarios/morning_needs.yaml
scenario:
  id: morning_needs
  name: "Morning Check-In"
  description: "Practice expressing how you feel in the morning"

nodes:
  - id: greeting
    prompt_video: "videos/greeting.mp4"
    prompt_gloss: "GOOD MORNING HOW YOU FEEL"
    expected_responses:
      - sign: TIRED
        next: tired_response
      - sign: HUNGRY
        next: hungry_response
      - sign: PAIN
        next: pain_response
      - sign: OKAY
        next: okay_response

  - id: hungry_response
    prompt_video: "videos/hungry_followup.mp4"
    prompt_gloss: "BREAKFAST WANT COFFEE WANT"
    expected_responses:
      - sign: COFFEE
        next: coffee_response
      - sign: WATER
        next: water_response
      - sign: PLEASE
        next: polite_response

  # ... more nodes
```

**Deliverables**:
- 4 complete conversation scenarios
- Pre-recorded response videos
- Conversation flow engine
- Practice history per scenario

---

## Timeline Summary

```
Week 1:     Phase 0 - Technical Validation
            â”œâ”€â”€ Hand tracking in home lighting
            â”œâ”€â”€ Video playback + camera split-screen
            â””â”€â”€ Record 5 sample sign videos
            GO/NO-GO DECISION

Weeks 2-3:  Phase 1 - Fingerspelling (A-Z)
            â”œâ”€â”€ Static pose recognition
            â”œâ”€â”€ Reference images/videos for alphabet
            â””â”€â”€ Basic practice UI
            GO/NO-GO DECISION

Weeks 4-6:  Phase 2 - Motion Signs (15 signs)
            â”œâ”€â”€ Motion recognition
            â”œâ”€â”€ Record/source 15 sign videos
            â””â”€â”€ Occlusion handling
            GO/NO-GO DECISION

Weeks 7-9:  Phase 3 - Learning Loop
            â”œâ”€â”€ Spaced repetition
            â”œâ”€â”€ Progress tracking
            â””â”€â”€ Daily practice
            GO/NO-GO DECISION

Weeks 10-14: Phase 4 - Conversations
            â”œâ”€â”€ Scenario engine
            â”œâ”€â”€ Pre-scripted dialogues
            â”œâ”€â”€ Record conversation videos
            â””â”€â”€ Two-way practice

TOTAL: 14 weeks to full MVP

TECH STACK (Simplified):
â€¢ SwiftUI (UI)
â€¢ AVFoundation (video playback)
â€¢ Vision Framework (hand tracking)
â€¢ CoreML (gesture recognition)
â€¢ NO Unity, NO RealityKit for MVP
```

---

## Risk Mitigation Summary

### P0 Issues (Addressed)

| Issue | Original | Mitigation |
|-------|----------|------------|
| Biometric privacy | No disclosure | Explicit consent + differential privacy |
| Emergency scenario | Included | **Removed from MVP** |

### P1 Issues (Eliminated)

| Issue | Original | Mitigation |
|-------|----------|------------|
| Unity-iOS stability | Complex integration | **Eliminated** - Video-only, pure iOS |
| RealityKit complexity | 3D rendering | **Eliminated** - Video-only approach |
| Hand occlusion | Full signs immediately | Start with fingerspelling, progressive complexity |
| Uncanny valley | 3D avatar | **Eliminated** - Real human in videos |

### P2 Issues (Addressed)

| Issue | Original | Mitigation |
|-------|----------|------------|
| No ASL generation model | Needed for avatar | **N/A** - Pre-recorded video |
| Dataset mismatch | Generic datasets | User's own data from Phase 3 |
| App size | Video files large | Compress H.264, optional CDN streaming |

---

## Budget Considerations

### MVP Cost (Video-Only Approach)

| Item | Cost | Notes |
|------|------|-------|
| Apple Developer Account | $99/year | Required for device testing |
| Supabase | $0 (free tier) | Sufficient for MVP |
| Video Production | $0-200 | Self-record or hire ASL tutor for 2-3 hours |
| Reference Images | $0 | Use ASL Alphabet dataset (public) |
| **Total MVP** | **~$100-300** | |

### Video Production Options

| Option | Cost | Quality | Time |
|--------|------|---------|------|
| Self-record | $0 | Learning quality | 2-4 hours |
| Family member who signs | $0 | Good | 2-4 hours |
| Hire ASL tutor | $50-100/hr | Professional | 2-3 hours |
| License existing videos | $100-500 | Professional | Immediate |

**Recommendation**: Start with self-recorded videos for Phase 0 validation. Upgrade to professional videos if app validates learning approach.

---

## Success Metrics

### MVP Success Criteria

```
MUST HAVE (Launch blockers):
â–¡ Fingerspelling A-Z works >90% accuracy
â–¡ 15 motion signs work >95% accuracy
â–¡ User practices daily for 2+ weeks
â–¡ Family members understand user's signs

SHOULD HAVE (Quality of life):
â–¡ <200ms feedback latency
â–¡ Works in kitchen/living room lighting
â–¡ Progress visible and motivating
â–¡ No crashes during 30-minute session

NICE TO HAVE (Delight):
â–¡ Streak tracking motivates daily practice
â–¡ Family members want to learn too
â–¡ User recommends to others
```

### Post-MVP Metrics (v2.0 Planning)

```
â–¡ Expand vocabulary to 100+ signs
â–¡ Add emergency signs (with 99%+ accuracy)
â–¡ Add family member accounts (learn together)
â–¡ Evaluate 3D avatar (RealityKit) - only if video approach needs enhancement
â–¡ Consider LLM integration (with proper ASL fine-tuning)
```

---

## Appendix: Removed Features (Future Versions)

### Emergency Scenario (v2.0+)
**Prerequisite**: Recognition accuracy >99% on safety signs
**Requirements**:
- Redundant confirmation (sign + button + voice if available)
- Direct 911 integration (not just "call doctor")
- Family member alert system
- Regular accuracy testing/recalibration

### LLM Conversation (v3.0+)
**Prerequisite**: Fine-tuned model on Englishâ†’ASL gloss
**Requirements**:
- Training data: 10K+ parallel sentences
- Gloss accuracy validation
- Hallucination guardrails
- Latency optimization (<500ms)

### 3D Avatar (v2.0+ - Only If Needed)
**Prerequisite**: Video-based MVP validates learning approach AND users request dynamic content
**Technology**: RealityKit (Apple native) - NOT Unity
**Requirements**:
- Prove video approach works first
- User research shows demand for dynamic avatar
- Motion capture session with native ASL signer
- Performance validation on target devices

**Decision Criteria for Adding 3D**:
- Users explicitly request it
- Conversation mode needs dynamic responses
- Video library becomes unmanageable (500+ signs)

---

## Next Steps

1. **Immediate**: Implement biometric consent flow (SignVerse-rdn)
2. **Phase 0**: Test Vision Framework in your home lighting
3. **Phase 0**: Build camera + video split-screen prototype
4. **Phase 0**: Record 5 sample sign videos

**Architecture Confirmed**: Pure iOS (SwiftUI + AVFoundation + Vision Framework)
**No Unity. No RealityKit for MVP.**

**Ready to start Phase 0 validation?**
